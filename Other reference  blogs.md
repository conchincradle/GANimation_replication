Reference: [人脸表情系列：代码阅读——GANimation: Anatomically-aware Facial Animation from a Single Image](https://blog.csdn.net/lynlindasy/article/details/96865515)
- 该表情生成算法是基于Action Unit的，因此首先要有images和其AU标签。根据readme文件，要根据data目录下的prepare_au_annotations.py文件生成pkl文件，该文件包含了AU标签。
- 训练过程如下：先固定生成器，通过self._forward_D()_ 前向传播得到判别器的结果，然后对判别器进行梯度下降（self._optimizer_D.zero_grad()，其中zero_grad()是对每一个batch的梯度进行清零，  
- 因为pytorch中的backward()中梯度是累积的）和反向传播（loss_D.backward()），然后对其进行更新（self._optimizer_D.step()）。  
- 由于我们使用的是WGAN，要对梯度进行penalty，因此有下面的loss_D_gp等步骤，最后如果要训练生成器，则开始对生成器进行前向传播计算loss_G，梯度下降，反向传播和参数更新
- GAN一般情况下的网络结构，在一些人的实验中已经表明对于要求高分辨率、高细节保持的图像领域中并不适合，有些人根据这一情况设计了PatchGAN的思路。
- 这种GAN的差别主要是在于Discriminator上，一般的GAN是只需要输出一个true or fasle 的矢量，这是代表对整张图像的评价；但是PatchGAN输出的是一个N x N的矩阵，这个N x N的矩阵的每一个元素，
- 比如a(i,j) 只有True or False 这两个选择（label 是 N x N的矩阵，每一个元素是True 或者 False），这样的结果往往是通过卷积层来达到的，
- 因为逐次叠加的卷积层最终输出的这个N x N 的矩阵，其中的每一个元素，实际上代表着原图中的一个比较大的感受野，
- 也就是说对应着原图中的一个Patch，因此具有这样结构以及这样输出的GAN被称之为Patch GAN
-[PatchGAN Discriminator](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/39)
- Which is patch ij in the input? Well, output X_ij is just a neuron in a convnet, 
- and we can trace back its receptive field to see which input pixels it is sensitive to. 
- In the CycleGAN architecture, the receptive fields of the discriminator turn out to be 70x70 patches in the input image!
